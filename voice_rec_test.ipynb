{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech to Text\n",
    "The purpose of this notebook is to prototype some code that can perform the following tasks\n",
    "\n",
    "*Part 1: Listening for Speech and Storing speech in FIFO buffer*\n",
    "- Detect and open the microphone on a MacBook Pro computer\n",
    "- Listen for any spoken words.\n",
    "- Create a list of strings that are all the spoken words \n",
    "- Add the heard words to a FIFO buuffer of heard words\n",
    "- include information about the part of speech for each word in the FIFO buffer\n",
    "\n",
    "*Part 2: Using FIFO buffer to construct prompts for Stable Diffusion*\n",
    "- Generate or use predefined prompt structures and the FIFO of spoken words to generate Stable Diffusion prompts\n",
    "\n",
    "*Part 3: Generate Images*\n",
    "- Feed generated prompts into a stable diffusion network to create images based on recent conversations that occur in the proximity of the laptop\n",
    "\n",
    "This notebook serves as a POC for an installation I am working on that passively listens to the environment it is installed and uses words spoken in the location and machine learning to create images based on what people are talking about =)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_words:  {\"wasn't\", 'couldn', 'it', 'yourself', \"wouldn't\", 'are', 'she', 'such', 'yours', \"she's\", 'these', 'above', 'further', 'having', 'nor', 'me', 'the', 'on', 'did', 'yourselves', 'there', 'mightn', 'needn', 'y', 'whom', 'in', \"isn't\", 'am', 'those', 'your', 'hasn', 'does', 'only', 'until', 'and', 'doing', 'each', 'wouldn', 'will', \"needn't\", 'a', 'ourselves', 'don', 'was', \"weren't\", 'has', 'i', 'more', 'just', 'that', 'off', \"mightn't\", 'than', \"doesn't\", 'herself', 'because', 'which', \"hasn't\", 'itself', \"that'll\", 'they', 've', 'for', 'hers', 'why', 'mustn', 'while', 'ain', \"it's\", 'being', 'again', 'by', 'its', 'we', 'how', 'through', 'he', 'into', \"couldn't\", 'from', 'here', 'an', 'between', 'won', 'himself', 'ours', 'up', \"mustn't\", 'some', 'out', 'themselves', 'against', 'as', 'him', 'other', 'once', 'after', 'our', 'what', 'to', 'doesn', 'where', 'own', \"you've\", 'have', 'm', 'not', 'same', \"won't\", 'very', 'her', 'aren', 'this', \"aren't\", 'of', \"haven't\", 'then', 'or', \"should've\", 'shan', \"don't\", 'is', \"you'd\", \"didn't\", 'had', 'few', 'if', \"shan't\", 'too', 'no', 'do', 'most', \"hadn't\", 'isn', 'over', \"you're\", 'so', 'under', 'll', 'them', 'with', 'didn', 'o', 'been', 'when', 'down', 'haven', 'during', 'be', 'who', 'theirs', 'd', 'any', 'were', 'now', 'can', 's', 'about', 'wasn', \"shouldn't\", 'hadn', 'below', 'but', 't', 're', 'my', 'shouldn', 'all', 'you', 'both', 'their', 'myself', \"you'll\", 'his', 'at', 'weren', 'ma', 'should', 'before'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/nathan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pyaudio as audio\n",
    "import speech_recognition as sr\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk import RegexpParser\n",
    "\n",
    "##############################\n",
    "only_unique_words = True\n",
    "###############\n",
    "\n",
    "# Download the required datafiles for the NLTK pos_tag function\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# create a list of stopwords to ignore...\n",
    "stopwords = set(['shan', 'same', \"wasn't\", \"she's\", \n",
    "                 'they', 'off', \"needn't\", \"weren't\", \n",
    "                 'as', 'some', 'and', 'from', 'other', \n",
    "                 \"shouldn't\", \"shan't\", 'to', 'does', \n",
    "                 'was', 'has', 'so', 'himself', 'do', \n",
    "                 'below', \"doesn't\", \"that'll\", 'its', \n",
    "                 'these', 'are', 'more', 'aren', 'all', \n",
    "                 'whom', 'shouldn', 'too', 'over', \"you've\", \n",
    "                 'him', 'o', 'his', 'be', \"you'll\", 'out', \n",
    "                 'against', 'most', 'if', 'hasn', 'own', \n",
    "                 's', 'what', 'theirs', 'or', \"it's\", \n",
    "                 'will', \"don't\", 'is', 'been', 'who', \n",
    "                 'yourselves', 'her', 'did', 'the', 'up', \n",
    "                 'there', 'ourselves', 'during', 'mightn', \n",
    "                 \"you'd\", 'further', 'very', 'those', 'for', \n",
    "                 'but', 'an', 'in', 'nor', \"mightn't\", 've', \n",
    "                 'both', 'until', 'isn', 'ain', \"didn't\", \n",
    "                 'than', 'themselves', 'myself', \"couldn't\", \n",
    "                 'now', 'herself', 'any', 'by', \"wouldn't\", \n",
    "                 'about', 'after', 'here', 'doesn', 'a', \n",
    "                 'which', 'd', 'y', 'were', 'couldn', \n",
    "                 \"aren't\", 'i', 'then', 'being', 'just', \n",
    "                 'our', \"haven't\", 't', 'wouldn', 're', \n",
    "                 \"mustn't\", 'while', 'with', 'only', \n",
    "                 'under', 'ma', 'again', 'can', 'ours', \n",
    "                 'through', \"hadn't\", 'when', 'hers', \n",
    "                 \"isn't\", 'of', 'few', 'my', 'had', \n",
    "                 'before', 'where', 'wasn', \"should've\", \n",
    "                 'she', 'your', 'haven', 'weren', 'on', \n",
    "                 'have', 'he', 'between', 'me', 'down', \n",
    "                 'should', 'mustn', 'their', 'am', 'above', \n",
    "                 'll', 'such', 'why', 'no', 'you', 'it', \n",
    "                 'because', 'into', 'm', \"you're\", 'that', \n",
    "                 'itself', 'not', 'hadn', \"won't\", 'we', \n",
    "                 'don', 'doing', 'won', 'them', 'this', \n",
    "                 \"hasn't\", 'how', 'at', 'needn', 'once', \n",
    "                 'having', 'yours', 'each', 'yourself', 'didn'])\n",
    "\n",
    "print(\"stop_words: \", stopwords)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# create a queue of the last 100 words identified by the program\n",
    "# recent_text_q is a list of dicts with three values: word, type, and freq\n",
    "recent_text_q = []\n",
    "max_q_len = 100\n",
    "\n",
    "# activate macbook microphone stream\n",
    "# create a speech recognition object\n",
    "recognizer = sr.Recognizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "################################################################\n",
    "## figure out what audio device our microphone is\n",
    "def getMacbookProMic():\n",
    "    print(sr.Microphone.list_microphone_names())\n",
    "    internal_macbook_name = \"MacBook Pro Microphone\"\n",
    "    index = sr.Microphone.list_microphone_names().index(internal_macbook_name)\n",
    "\n",
    "    print(\"should be the internal microphone: \", sr.Microphone.list_microphone_names()[index])\n",
    "\n",
    "    # create a microphone object\n",
    "    internal_mic = sr.Microphone(device_index = index)\n",
    "    return internal_mic\n",
    "\n",
    "def fifoInDict(lst, val, tag, max_len):\n",
    "    # check if item needs to be removed\n",
    "    if len(lst) >= max_len:\n",
    "        lst.pop(0)\n",
    "    # update the dictionary\n",
    "    temp_dict = {'word': val, 'type': tag, 'freq': 1}\n",
    "    lst.append(temp_dict)\n",
    "    return lst\n",
    "\n",
    "def fifoInLst(lst, val, max_len):\n",
    "    # check if item needs to be removed\n",
    "    if len(lst) >= max_len:\n",
    "        lst.pop(0)\n",
    "    # update the dictionary\n",
    "    lst.append(val)\n",
    "    return lst\n",
    "\n",
    "def speechToText(mic, recognizer):\n",
    "    \"\"\"\n",
    "    Input : mic = st.Microphone() object where an audio stream can be read\n",
    "            recognizer = sr.Recognizer() object that takes in a audio clip and returns a list of words\n",
    "    Output: words = list of words that are identified from words spoken into the microphone\n",
    "    \"\"\"\n",
    "    # capture audio from the microphone\n",
    "    with mic as source:\n",
    "        # adjust for background noise to increase success rate\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        # identify any spoken words in the audio\n",
    "        print(\"Speech Recognizer Enabled\");\n",
    "        audio = recognizer.listen(source)\n",
    "        print(\"audio exported from source\")\n",
    "        raw_string = \"\"\n",
    "        try:\n",
    "            raw_string = recognizer.recognize_google(audio)\n",
    "        except:\n",
    "            print(\" .\")\n",
    "\n",
    "        print(\"{} of tokenized words returned from google: {}\".format(type(raw_string), raw_string))\n",
    "        # remove words from string\n",
    "\n",
    "        return_str = raw_string.split()\n",
    "        wn = len(return_str)\n",
    "        # remove any words in the stopwords\n",
    "        words = [i for i in return_str if i not in stopwords]\n",
    "        print(\"{} words removed from stopwords\".format(wn - len(words)))\n",
    "        words = [i for i in return_str if i not in recent_text_q]\n",
    "        print(\"{} words removed from priorwords\".format(wn - len(words)))\n",
    "        return words\n",
    "    \n",
    "def tagWords(words):\n",
    "    \"\"\"\n",
    "    Use NLTK to tag a list of words and return a tuple (str, type)\n",
    "    This function should be run before storing the words into memory so the program\n",
    "    knows what part of speech the words belong and can construct sentences from those\n",
    "    words accordingly\n",
    "    \"\"\"\n",
    "    words_tags = pos_tag(words)\n",
    "    print(\"words tagged: {}\".format(words_tags))\n",
    "    return words_tags\n",
    "\n",
    "def addWordsToMemory(words, tags):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    # create a dict to place in the list of heard words\n",
    "    # append spoken words to the running FIFO of all words\n",
    "    for i in range(words):\n",
    "        recent_text_q = fifoInDict(recent_text_q, words[i], tags[i], max_q_len)\n",
    "        # if append to buffer according to type of grammer\n",
    "\n",
    "    print(\"{} identified words: \".format(len(recent_text_q)),\n",
    "            recent_text_q)\n",
    "    return recent_text_q\n",
    "\n",
    "# classify words and add them to FIFO buffers\n",
    "\n",
    "# print current FIFO buffers\n",
    "\n",
    "def getStrFromTuple(lst):\n",
    "    r = \"\"\n",
    "    for l in lst:\n",
    "        r.join(l[0]).join(\" \")\n",
    "    return r\n",
    "\n",
    "def getStrFromList(lst):\n",
    "    print(lst)\n",
    "    r = \"\"\n",
    "    for i in range(len(lst)):\n",
    "        print(i)\n",
    "        r.join(lst[i]).join(\" \")\n",
    "        print(r)\n",
    "    return r\n",
    "\n",
    "def createWordDict(word_tags):\n",
    "    word_dict = {}\n",
    "    for word, pos in word_tags:\n",
    "        if word in word_dict:\n",
    "            word_dict[word][\"freq\"] += 1\n",
    "        else:\n",
    "            word_dict[word] = {\"word\": word, \"type\": pos, \"freq\": 1}\n",
    "\n",
    "    consolidated_list = list(word_dict.values())\n",
    "    return consolidated_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Speech to Text Portion of the Program\n",
    "Okay great, now we have all the functions we need to detect the MacBook Pro microphone, open it,\n",
    "listen for a while, and then extract the spoken text. We also have functions to remove stop words,\n",
    "and tag the words with what part of speech they belong to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LG HDR 4K', 'BlackHole 16ch', 'MacBook Pro Microphone', 'MacBook Pro Speakers', 'Microsoft Teams Audio', 'ZoomAudioDevice']\n",
      "should be the internal microphone:  MacBook Pro Microphone\n",
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "[]\n",
      " .\n",
      "<class 'str'> of tokenized words returned from google: \n",
      "0 words removed from stopwords\n",
      "0 words removed from priorwords\n",
      "List of 0 words includes: []\n",
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "[]\n",
      " .\n",
      "<class 'str'> of tokenized words returned from google: \n",
      "0 words removed from stopwords\n",
      "0 words removed from priorwords\n",
      "List of 0 words includes: []\n",
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "[]\n",
      " .\n",
      "<class 'str'> of tokenized words returned from google: \n",
      "0 words removed from stopwords\n",
      "0 words removed from priorwords\n",
      "List of 0 words includes: []\n",
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "[]\n",
      " .\n",
      "<class 'str'> of tokenized words returned from google: \n",
      "0 words removed from stopwords\n",
      "0 words removed from priorwords\n",
      "List of 0 words includes: []\n",
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "[]\n",
      " .\n",
      "<class 'str'> of tokenized words returned from google: \n",
      "0 words removed from stopwords\n",
      "0 words removed from priorwords\n",
      "List of 0 words includes: []\n",
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "[]\n",
      " .\n",
      "<class 'str'> of tokenized words returned from google: \n",
      "0 words removed from stopwords\n",
      "0 words removed from priorwords\n",
      "List of 0 words includes: []\n",
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "[]\n",
      " .\n",
      "<class 'str'> of tokenized words returned from google: \n",
      "0 words removed from stopwords\n",
      "0 words removed from priorwords\n",
      "List of 0 words includes: []\n",
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.71555811,\n",
      "                           'transcript': 'how much the shows were costing and '\n",
      "                                         'production for being run at the '\n",
      "                                         'recruiting onset and wasted many '\n",
      "                                         'working there thought were '\n",
      "                                         'completely unnecessary and Beyond'},\n",
      "                       {   'transcript': 'how much the shows were costing and '\n",
      "                                         'production for being run recruiting '\n",
      "                                         'onset and wasted many working there '\n",
      "                                         'thought were completely unnecessary '\n",
      "                                         'and Beyond'},\n",
      "                       {   'transcript': 'how much the shows were costing and '\n",
      "                                         'production for being run at the '\n",
      "                                         'recruiting onset and wasted many '\n",
      "                                         'working their thought were '\n",
      "                                         'completely unnecessary and Beyond'},\n",
      "                       {   'transcript': 'how much the shows for costing and '\n",
      "                                         'production for being run at the '\n",
      "                                         'recruiting onset and wasted many '\n",
      "                                         'working there thought were '\n",
      "                                         'completely unnecessary and Beyond'},\n",
      "                       {   'transcript': 'how much the shows were costing and '\n",
      "                                         'how the production for being run at '\n",
      "                                         'the recruiting onset and wasted many '\n",
      "                                         'working there thought were '\n",
      "                                         'completely unnecessary and Beyond'}],\n",
      "    'final': True}\n",
      "<class 'str'> of tokenized words returned from google: how much the shows were costing and production for being run at the recruiting onset and wasted many working there thought were completely unnecessary and Beyond\n",
      "12 words removed from stopwords\n",
      "0 words removed from priorwords\n",
      "List of 26 words includes: ['how', 'much', 'the', 'shows', 'were', 'costing', 'and', 'production', 'for', 'being', 'run', 'at', 'the', 'recruiting', 'onset', 'and', 'wasted', 'many', 'working', 'there', 'thought']\n",
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "[]\n",
      " .\n",
      "<class 'str'> of tokenized words returned from google: \n",
      "0 words removed from stopwords\n",
      "0 words removed from priorwords\n",
      "List of 26 words includes: ['how', 'much', 'the', 'shows', 'were', 'costing', 'and', 'production', 'for', 'being', 'run', 'at', 'the', 'recruiting', 'onset', 'and', 'wasted', 'many', 'working', 'there', 'thought']\n",
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "[]\n",
      " .\n",
      "<class 'str'> of tokenized words returned from google: \n",
      "0 words removed from stopwords\n",
      "0 words removed from priorwords\n",
      "List of 26 words includes: ['how', 'much', 'the', 'shows', 'were', 'costing', 'and', 'production', 'for', 'being', 'run', 'at', 'the', 'recruiting', 'onset', 'and', 'wasted', 'many', 'working', 'there', 'thought']\n",
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "[]\n",
      " .\n",
      "<class 'str'> of tokenized words returned from google: \n",
      "0 words removed from stopwords\n",
      "0 words removed from priorwords\n",
      "List of 26 words includes: ['how', 'much', 'the', 'shows', 'were', 'costing', 'and', 'production', 'for', 'being', 'run', 'at', 'the', 'recruiting', 'onset', 'and', 'wasted', 'many', 'working', 'there', 'thought']\n",
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.91986722,\n",
      "                           'transcript': 'writing and producing'},\n",
      "                       {'transcript': 'writing introducing'}],\n",
      "    'final': True}\n",
      "<class 'str'> of tokenized words returned from google: writing and producing\n",
      "1 words removed from stopwords\n",
      "0 words removed from priorwords\n",
      "List of 29 words includes: ['how', 'much', 'the', 'shows', 'were', 'costing', 'and', 'production', 'for', 'being', 'run', 'at', 'the', 'recruiting', 'onset', 'and', 'wasted', 'many', 'working', 'there', 'thought', 'were', 'completely', 'unnecessary']\n",
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "{   'alternative': [{'confidence': 0.88903779, 'transcript': 'employees'}],\n",
      "    'final': True}\n",
      "<class 'str'> of tokenized words returned from google: employees\n",
      "0 words removed from stopwords\n",
      "0 words removed from priorwords\n",
      "List of 30 words includes: ['how', 'much', 'the', 'shows', 'were', 'costing', 'and', 'production', 'for', 'being', 'run', 'at', 'the', 'recruiting', 'onset', 'and', 'wasted', 'many', 'working', 'there', 'thought', 'were', 'completely', 'unnecessary', 'and']\n",
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "[]\n",
      " .\n",
      "<class 'str'> of tokenized words returned from google: \n",
      "0 words removed from stopwords\n",
      "0 words removed from priorwords\n",
      "List of 30 words includes: ['how', 'much', 'the', 'shows', 'were', 'costing', 'and', 'production', 'for', 'being', 'run', 'at', 'the', 'recruiting', 'onset', 'and', 'wasted', 'many', 'working', 'there', 'thought', 'were', 'completely', 'unnecessary', 'and']\n",
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "[]\n",
      " .\n",
      "<class 'str'> of tokenized words returned from google: \n",
      "0 words removed from stopwords\n",
      "0 words removed from priorwords\n",
      "List of 30 words includes: ['how', 'much', 'the', 'shows', 'were', 'costing', 'and', 'production', 'for', 'being', 'run', 'at', 'the', 'recruiting', 'onset', 'and', 'wasted', 'many', 'working', 'there', 'thought', 'were', 'completely', 'unnecessary', 'and']\n",
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "[]\n",
      " .\n",
      "<class 'str'> of tokenized words returned from google: \n",
      "0 words removed from stopwords\n",
      "0 words removed from priorwords\n",
      "List of 30 words includes: ['how', 'much', 'the', 'shows', 'were', 'costing', 'and', 'production', 'for', 'being', 'run', 'at', 'the', 'recruiting', 'onset', 'and', 'wasted', 'many', 'working', 'there', 'thought', 'were', 'completely', 'unnecessary', 'and']\n",
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "[]\n",
      " .\n",
      "<class 'str'> of tokenized words returned from google: \n",
      "0 words removed from stopwords\n",
      "0 words removed from priorwords\n",
      "List of 30 words includes: ['how', 'much', 'the', 'shows', 'were', 'costing', 'and', 'production', 'for', 'being', 'run', 'at', 'the', 'recruiting', 'onset', 'and', 'wasted', 'many', 'working', 'there', 'thought', 'were', 'completely', 'unnecessary', 'and']\n",
      "Speech Recognizer Enabled\n",
      "audio exported from source\n",
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.80914599,\n",
      "                           'transcript': \"there's a lot of words that I want \"\n",
      "                                         'to talk about and things can get '\n",
      "                                         'real ugly and scary and manipulative '\n",
      "                                         'and a whole bunch of things like '\n",
      "                                         'that my question is really can you '\n",
      "                                         'understand the words are coming out '\n",
      "                                         'of my mouth can you make sense of '\n",
      "                                         'them or not'},\n",
      "                       {   'transcript': \"there's a lot of words that I want \"\n",
      "                                         'to talk about and things can get '\n",
      "                                         'real ugly and scary and manipulative '\n",
      "                                         'and a whole bunch of things like '\n",
      "                                         'that my question is really can you '\n",
      "                                         'understand the words that are coming '\n",
      "                                         'out of my mouth can you make sense '\n",
      "                                         'of them or not'},\n",
      "                       {   'transcript': \"so there's a lot of words that I \"\n",
      "                                         'want to talk about and things can '\n",
      "                                         'get real ugly and scary and '\n",
      "                                         'manipulative and a whole bunch of '\n",
      "                                         'things like that my question is '\n",
      "                                         'really can you understand the words '\n",
      "                                         'are coming out of my mouth can you '\n",
      "                                         'make sense of them or not'},\n",
      "                       {   'transcript': \"so there's a lot of words that I \"\n",
      "                                         'want to talk about and things can '\n",
      "                                         'get real ugly and scary and '\n",
      "                                         'manipulative and a whole bunch of '\n",
      "                                         'things like that my question is '\n",
      "                                         'really can you understand the words '\n",
      "                                         'that are coming out of my mouth can '\n",
      "                                         'you make sense of them or not'},\n",
      "                       {   'transcript': \"but there's a lot of words that I \"\n",
      "                                         'want to talk about and things can '\n",
      "                                         'get real ugly and scary and '\n",
      "                                         'manipulative and a whole bunch of '\n",
      "                                         'things like that my question is '\n",
      "                                         'really can you understand the words '\n",
      "                                         'are coming out of my mouth can you '\n",
      "                                         'make sense of them or not'}],\n",
      "    'final': True}\n",
      "<class 'str'> of tokenized words returned from google: there's a lot of words that I want to talk about and things can get real ugly and scary and manipulative and a whole bunch of things like that my question is really can you understand the words are coming out of my mouth can you make sense of them or not\n",
      "28 words removed from stopwords\n",
      "0 words removed from priorwords\n",
      "List of 82 words includes: ['how', 'much', 'the', 'shows', 'were', 'costing', 'and', 'production', 'for', 'being', 'run', 'at', 'the', 'recruiting', 'onset', 'and', 'wasted', 'many', 'working', 'there', 'thought', 'were', 'completely', 'unnecessary', 'and', 'Beyond', 'writing', 'and', 'producing', 'employees', \"there's\", 'a', 'lot', 'of', 'words', 'that', 'I', 'want', 'to', 'talk', 'about', 'and', 'things', 'can', 'get', 'real', 'ugly', 'and', 'scary', 'and', 'manipulative', 'and', 'a', 'whole', 'bunch', 'of', 'things', 'like', 'that', 'my', 'question', 'is', 'really', 'can', 'you', 'understand', 'the', 'words', 'are', 'coming', 'out', 'of', 'my', 'mouth', 'can', 'you', 'make']\n",
      "we found a total of 82 words: ['how', 'much', 'the', 'shows', 'were', 'costing', 'and', 'production', 'for', 'being', 'run', 'at', 'the', 'recruiting', 'onset', 'and', 'wasted', 'many', 'working', 'there', 'thought', 'were', 'completely', 'unnecessary', 'and', 'Beyond', 'writing', 'and', 'producing', 'employees', \"there's\", 'a', 'lot', 'of', 'words', 'that', 'I', 'want', 'to', 'talk', 'about', 'and', 'things', 'can', 'get', 'real', 'ugly', 'and', 'scary', 'and', 'manipulative', 'and', 'a', 'whole', 'bunch', 'of', 'things', 'like', 'that', 'my', 'question', 'is', 'really', 'can', 'you', 'understand', 'the', 'words', 'are', 'coming', 'out', 'of', 'my', 'mouth', 'can', 'you', 'make', 'sense', 'of', 'them', 'or', 'not']\n"
     ]
    }
   ],
   "source": [
    "# keep listening until 50 words are heard and stored in memory\n",
    "def listenForWords(min_words, max_words):\n",
    "    new_words = []\n",
    "    macbook_mic = getMacbookProMic()\n",
    "    while len(new_words) < min_words:\n",
    "        results = speechToText(macbook_mic, recognizer)\n",
    "        if results is not []:\n",
    "            new_words.extend(results)\n",
    "            print(\"List of {} words includes: {}\".format(len(new_words), new_words[:-5]))\n",
    "        else:\n",
    "            print(\"No words detected\")\n",
    "    return new_words[:max_words]\n",
    "\n",
    "words = listenForWords(20, 100)\n",
    "print('we found a total of {} words: {}'.format(len(words), words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words tagged: [('how', 'WRB'), ('much', 'JJ'), ('the', 'DT'), ('shows', 'NNS'), ('were', 'VBD'), ('costing', 'VBG'), ('and', 'CC'), ('production', 'NN'), ('for', 'IN'), ('being', 'VBG'), ('run', 'VBN'), ('at', 'IN'), ('the', 'DT'), ('recruiting', 'NN'), ('onset', 'NN'), ('and', 'CC'), ('wasted', 'VBD'), ('many', 'JJ'), ('working', 'VBG'), ('there', 'RB'), ('thought', 'VBN'), ('were', 'VBD'), ('completely', 'RB'), ('unnecessary', 'JJ'), ('and', 'CC'), ('Beyond', 'NNP'), ('writing', 'NN'), ('and', 'CC'), ('producing', 'VBG'), ('employees', 'NNS'), (\"there's\", 'VBP'), ('a', 'DT'), ('lot', 'NN'), ('of', 'IN'), ('words', 'NNS'), ('that', 'WDT'), ('I', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('talk', 'VB'), ('about', 'IN'), ('and', 'CC'), ('things', 'NNS'), ('can', 'MD'), ('get', 'VB'), ('real', 'JJ'), ('ugly', 'RB'), ('and', 'CC'), ('scary', 'JJ'), ('and', 'CC'), ('manipulative', 'JJ'), ('and', 'CC'), ('a', 'DT'), ('whole', 'JJ'), ('bunch', 'NN'), ('of', 'IN'), ('things', 'NNS'), ('like', 'IN'), ('that', 'DT'), ('my', 'PRP$'), ('question', 'NN'), ('is', 'VBZ'), ('really', 'RB'), ('can', 'MD'), ('you', 'PRP'), ('understand', 'VB'), ('the', 'DT'), ('words', 'NNS'), ('are', 'VBP'), ('coming', 'VBG'), ('out', 'IN'), ('of', 'IN'), ('my', 'PRP$'), ('mouth', 'NN'), ('can', 'MD'), ('you', 'PRP'), ('make', 'VB'), ('sense', 'NN'), ('of', 'IN'), ('them', 'PRP'), ('or', 'CC'), ('not', 'RB')]\n",
      "[{'word': 'how', 'type': 'WRB', 'freq': 1}, {'word': 'much', 'type': 'JJ', 'freq': 1}, {'word': 'the', 'type': 'DT', 'freq': 3}, {'word': 'shows', 'type': 'NNS', 'freq': 1}, {'word': 'were', 'type': 'VBD', 'freq': 2}, {'word': 'costing', 'type': 'VBG', 'freq': 1}, {'word': 'and', 'type': 'CC', 'freq': 8}, {'word': 'production', 'type': 'NN', 'freq': 1}, {'word': 'for', 'type': 'IN', 'freq': 1}, {'word': 'being', 'type': 'VBG', 'freq': 1}, {'word': 'run', 'type': 'VBN', 'freq': 1}, {'word': 'at', 'type': 'IN', 'freq': 1}, {'word': 'recruiting', 'type': 'NN', 'freq': 1}, {'word': 'onset', 'type': 'NN', 'freq': 1}, {'word': 'wasted', 'type': 'VBD', 'freq': 1}, {'word': 'many', 'type': 'JJ', 'freq': 1}, {'word': 'working', 'type': 'VBG', 'freq': 1}, {'word': 'there', 'type': 'RB', 'freq': 1}, {'word': 'thought', 'type': 'VBN', 'freq': 1}, {'word': 'completely', 'type': 'RB', 'freq': 1}, {'word': 'unnecessary', 'type': 'JJ', 'freq': 1}, {'word': 'Beyond', 'type': 'NNP', 'freq': 1}, {'word': 'writing', 'type': 'NN', 'freq': 1}, {'word': 'producing', 'type': 'VBG', 'freq': 1}, {'word': 'employees', 'type': 'NNS', 'freq': 1}, {'word': \"there's\", 'type': 'VBP', 'freq': 1}, {'word': 'a', 'type': 'DT', 'freq': 2}, {'word': 'lot', 'type': 'NN', 'freq': 1}, {'word': 'of', 'type': 'IN', 'freq': 4}, {'word': 'words', 'type': 'NNS', 'freq': 2}, {'word': 'that', 'type': 'WDT', 'freq': 2}, {'word': 'I', 'type': 'PRP', 'freq': 1}, {'word': 'want', 'type': 'VBP', 'freq': 1}, {'word': 'to', 'type': 'TO', 'freq': 1}, {'word': 'talk', 'type': 'VB', 'freq': 1}, {'word': 'about', 'type': 'IN', 'freq': 1}, {'word': 'things', 'type': 'NNS', 'freq': 2}, {'word': 'can', 'type': 'MD', 'freq': 3}, {'word': 'get', 'type': 'VB', 'freq': 1}, {'word': 'real', 'type': 'JJ', 'freq': 1}, {'word': 'ugly', 'type': 'RB', 'freq': 1}, {'word': 'scary', 'type': 'JJ', 'freq': 1}, {'word': 'manipulative', 'type': 'JJ', 'freq': 1}, {'word': 'whole', 'type': 'JJ', 'freq': 1}, {'word': 'bunch', 'type': 'NN', 'freq': 1}, {'word': 'like', 'type': 'IN', 'freq': 1}, {'word': 'my', 'type': 'PRP$', 'freq': 2}, {'word': 'question', 'type': 'NN', 'freq': 1}, {'word': 'is', 'type': 'VBZ', 'freq': 1}, {'word': 'really', 'type': 'RB', 'freq': 1}, {'word': 'you', 'type': 'PRP', 'freq': 2}, {'word': 'understand', 'type': 'VB', 'freq': 1}, {'word': 'are', 'type': 'VBP', 'freq': 1}, {'word': 'coming', 'type': 'VBG', 'freq': 1}, {'word': 'out', 'type': 'IN', 'freq': 1}, {'word': 'mouth', 'type': 'NN', 'freq': 1}, {'word': 'make', 'type': 'VB', 'freq': 1}, {'word': 'sense', 'type': 'NN', 'freq': 1}, {'word': 'them', 'type': 'PRP', 'freq': 1}, {'word': 'or', 'type': 'CC', 'freq': 1}, {'word': 'not', 'type': 'RB', 'freq': 1}]\n"
     ]
    }
   ],
   "source": [
    "word_tags = tagWords(words)\n",
    "recent_text_q = createWordDict(word_tags)\n",
    "print(recent_text_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word : {'word': 'how', 'type': 'WRB', 'freq': 1}\n",
      "word : {'word': 'much', 'type': 'JJ', 'freq': 1}\n",
      "word : {'word': 'the', 'type': 'DT', 'freq': 3}\n",
      "word : {'word': 'shows', 'type': 'NNS', 'freq': 1}\n",
      "word : {'word': 'were', 'type': 'VBD', 'freq': 2}\n",
      "word : {'word': 'costing', 'type': 'VBG', 'freq': 1}\n",
      "word : {'word': 'and', 'type': 'CC', 'freq': 8}\n",
      "word : {'word': 'production', 'type': 'NN', 'freq': 1}\n",
      "word : {'word': 'for', 'type': 'IN', 'freq': 1}\n",
      "word : {'word': 'being', 'type': 'VBG', 'freq': 1}\n",
      "word : {'word': 'run', 'type': 'VBN', 'freq': 1}\n",
      "word : {'word': 'at', 'type': 'IN', 'freq': 1}\n",
      "word : {'word': 'recruiting', 'type': 'NN', 'freq': 1}\n",
      "word : {'word': 'onset', 'type': 'NN', 'freq': 1}\n",
      "word : {'word': 'wasted', 'type': 'VBD', 'freq': 1}\n",
      "word : {'word': 'many', 'type': 'JJ', 'freq': 1}\n",
      "word : {'word': 'working', 'type': 'VBG', 'freq': 1}\n",
      "word : {'word': 'there', 'type': 'RB', 'freq': 1}\n",
      "word : {'word': 'thought', 'type': 'VBN', 'freq': 1}\n",
      "word : {'word': 'completely', 'type': 'RB', 'freq': 1}\n",
      "word : {'word': 'unnecessary', 'type': 'JJ', 'freq': 1}\n",
      "word : {'word': 'Beyond', 'type': 'NNP', 'freq': 1}\n",
      "word : {'word': 'writing', 'type': 'NN', 'freq': 1}\n",
      "word : {'word': 'producing', 'type': 'VBG', 'freq': 1}\n",
      "word : {'word': 'employees', 'type': 'NNS', 'freq': 1}\n",
      "word : {'word': \"there's\", 'type': 'VBP', 'freq': 1}\n",
      "word : {'word': 'a', 'type': 'DT', 'freq': 2}\n",
      "word : {'word': 'lot', 'type': 'NN', 'freq': 1}\n",
      "word : {'word': 'of', 'type': 'IN', 'freq': 4}\n",
      "word : {'word': 'words', 'type': 'NNS', 'freq': 2}\n",
      "word : {'word': 'that', 'type': 'WDT', 'freq': 2}\n",
      "word : {'word': 'I', 'type': 'PRP', 'freq': 1}\n",
      "word : {'word': 'want', 'type': 'VBP', 'freq': 1}\n",
      "word : {'word': 'to', 'type': 'TO', 'freq': 1}\n",
      "word : {'word': 'talk', 'type': 'VB', 'freq': 1}\n",
      "word : {'word': 'about', 'type': 'IN', 'freq': 1}\n",
      "word : {'word': 'things', 'type': 'NNS', 'freq': 2}\n",
      "word : {'word': 'can', 'type': 'MD', 'freq': 3}\n",
      "word : {'word': 'get', 'type': 'VB', 'freq': 1}\n",
      "word : {'word': 'real', 'type': 'JJ', 'freq': 1}\n",
      "word : {'word': 'ugly', 'type': 'RB', 'freq': 1}\n",
      "word : {'word': 'scary', 'type': 'JJ', 'freq': 1}\n",
      "word : {'word': 'manipulative', 'type': 'JJ', 'freq': 1}\n",
      "word : {'word': 'whole', 'type': 'JJ', 'freq': 1}\n",
      "word : {'word': 'bunch', 'type': 'NN', 'freq': 1}\n",
      "word : {'word': 'like', 'type': 'IN', 'freq': 1}\n",
      "word : {'word': 'my', 'type': 'PRP$', 'freq': 2}\n",
      "word : {'word': 'question', 'type': 'NN', 'freq': 1}\n",
      "word : {'word': 'is', 'type': 'VBZ', 'freq': 1}\n",
      "word : {'word': 'really', 'type': 'RB', 'freq': 1}\n",
      "word : {'word': 'you', 'type': 'PRP', 'freq': 2}\n",
      "word : {'word': 'understand', 'type': 'VB', 'freq': 1}\n",
      "word : {'word': 'are', 'type': 'VBP', 'freq': 1}\n",
      "word : {'word': 'coming', 'type': 'VBG', 'freq': 1}\n",
      "word : {'word': 'out', 'type': 'IN', 'freq': 1}\n",
      "word : {'word': 'mouth', 'type': 'NN', 'freq': 1}\n",
      "word : {'word': 'make', 'type': 'VB', 'freq': 1}\n",
      "word : {'word': 'sense', 'type': 'NN', 'freq': 1}\n",
      "word : {'word': 'them', 'type': 'PRP', 'freq': 1}\n",
      "word : {'word': 'or', 'type': 'CC', 'freq': 1}\n",
      "word : {'word': 'not', 'type': 'RB', 'freq': 1}\n",
      "16 nouns are saved: ['shows', 'production', 'recruiting', 'onset', 'Beyond', 'writing', 'employees', 'lot', 'words', 'words', 'things', 'things', 'bunch', 'question', 'mouth', 'sense']\n",
      "18 verbs are saved: ['were', 'were', 'costing', 'being', 'run', 'wasted', 'working', 'thought', 'producing', \"there's\", 'want', 'talk', 'get', 'is', 'understand', 'are', 'coming', 'make']\n",
      "7 adjectives are saved: ['much', 'many', 'unnecessary', 'real', 'scary', 'manipulative', 'whole']\n"
     ]
    }
   ],
   "source": [
    "nouns = []\n",
    "verbs = []\n",
    "adjectives = []\n",
    "\n",
    "def populateGrammarLists(recent_text_q, nouns, verbs, adjectives):\n",
    "    for word in recent_text_q:\n",
    "        print(\"word : {}\".format(word))\n",
    "        if word['type'].startswith(\"NN\"):\n",
    "            for i in range(word['freq']):\n",
    "                nouns = fifoInLst(nouns, word['word'], max_q_len)\n",
    "        elif word['type'].startswith(\"VB\"):\n",
    "            for i in range(word['freq']):\n",
    "                verbs = fifoInLst(verbs, word['word'], max_q_len)\n",
    "        elif word['type'].startswith(\"JJ\"):\n",
    "            for i in range(word['freq']):\n",
    "                adjectives = fifoInLst(adjectives, word['word'], max_q_len)\n",
    "        prompt_string = \"\"\n",
    "    return nouns, verbs, adjectives\n",
    "\n",
    "nouns, verbs, adjectives = populateGrammarLists(recent_text_q, nouns, verbs, adjectives)\n",
    "print(\"{} nouns are saved: {}\".format(len(nouns), nouns))\n",
    "print(\"{} verbs are saved: {}\".format(len(verbs), verbs))\n",
    "print(\"{} adjectives are saved: {}\".format(len(adjectives), adjectives))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to Speech using espeak in OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cubist painting with abstract styling and high detail shows scary words coming question, lot unnecessary mouth run bunch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# okay, now it is time to construct our string\n",
    "\n",
    "def addSimplePhraise():\n",
    "    # generate multiple phraises, then determine best one using nltk\n",
    "    return \"{} {} {} {} {}\".format(randomNoun(), randomAdj(), randomNoun(), randomVerb(), randomNoun())\n",
    "\n",
    "def randomNoun():\n",
    "    return nouns[random.randint(0, len(nouns) - 1)]\n",
    "\n",
    "def randomVerb():\n",
    "    return verbs[random.randint(0, len(verbs) - 1)]\n",
    "\n",
    "def randomAdj():\n",
    "    return adjectives[random.randint(0, len(adjectives) - 1)]\n",
    "\n",
    "prompt_string = \"Cubist painting with abstract styling and high detail {}, {}\".format(addSimplePhraise(), addSimplePhraise())\n",
    "print(prompt_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using espeak to say the following command Cubist painting with abstract styling and high detail shows scary words coming question, lot unnecessary mouth run bunch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender = 'm' # as oppose to  'f'\n",
    "vnum = str(random.randint(1, 5))\n",
    "voice = '{}{}'.format(gender, vnum)\n",
    "pitch = str(random.randint(10, 90))\n",
    "command = 'espeak -s 180 -v {} -p {} \"{}\"\\n'.format(voice, pitch, prompt_string)\n",
    "print(\"using espeak to say the following command {}\".format(prompt_string))\n",
    "os.system(command)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great! Now lets use the stable diffusion repo located in ../stable_diffusion to then use our generated prompts to create some images!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../stable_diffusion')\n",
    "\n",
    "import image_generator_from_text as img_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_width': 512, 'output_height': 512, 'prompts': ['Cubist painting with abstract styling and high detail shows scary words coming question, lot unnecessary mouth run bunch'], 'batch_size': 1, 'steps': 10, 'seed': 1290, 'plot_output': True, 'upscale': 2.0}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "The main function of image_generator_from_text reads in a dictionary \n",
    "for arguments which needs the following fields:\n",
    "output_width\n",
    "output_height\n",
    "prompts\n",
    "batch_size\n",
    "steps\n",
    "seed\n",
    "plot_output\n",
    "upscale\n",
    "\"\"\"\n",
    "arg_dict = {\n",
    "    'output_width': 512,\n",
    "    'output_height': 512,\n",
    "    'prompts': [prompt_string],\n",
    "    'batch_size': 1,\n",
    "    'steps' : 10,\n",
    "    'seed' : 1290,\n",
    "    'plot_output': True,\n",
    "    'upscale': 2.0\n",
    "}\n",
    "print(arg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By using this model checkpoint, you acknowledge that its usage is subject to the terms of the CreativeML Open RAIL-M license at https://raw.githubusercontent.com/CompVis/stable-diffusion/main/LICENSE\n",
      "prompts are: ['Cubist painting with abstract styling and high detail shows scary words coming question, lot unnecessary mouth run bunch']\n",
      "prompts are ['Cubist painting with abstract styling and high detail shows scary words coming question, lot unnecessary mouth run bunch']\n",
      "image name generated: /Users/nathan/workspace/neural_art_bots/audio_transcription/output_images/2023_05_13_11_Cubist_painting_with_abstract_styling_an_s1290_0.png\n",
      "output names: ['/Users/nathan/workspace/neural_art_bots/audio_transcription/output_images/2023_05_13_11_Cubist_painting_with_abstract_styling_an_s1290_0.png']\n",
      "creating batch # 0 for prompt Cubist painting with abstract styling and high detail shows scary words coming question, lot unnecessary mouth run bunch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 11:22:29.332383: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [1,77]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-13 11:22:34.444034: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [1,77]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-13 11:22:55.167584: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 45 calls to <function Model.make_predict_function.<locals>.predict_function at 0x17e3a0dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 45 calls to <function Model.make_predict_function.<locals>.predict_function at 0x17e3a0dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-05-13 11:23:36.054224: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/10 [==>...........................] - ETA: 9:53"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 11:23:40.434562: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 11:23:44.723726: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/10 [=====>........................] - ETA: 1:08"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 11:23:49.029683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 11:23:53.461161: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/10 [========>.....................] - ETA: 1:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 11:23:57.989476: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 11:24:02.511233: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/10 [===========>..................] - ETA: 53s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 11:24:07.070765: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 11:24:12.736263: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/10 [==============>...............] - ETA: 52s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 11:24:22.791731: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 11:24:32.465861: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/10 [=================>............] - ETA: 46s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 11:24:38.338400: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 11:24:43.112519: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/10 [====================>.........] - ETA: 33s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 11:24:47.689040: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 11:24:52.811190: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8/10 [=======================>......] - ETA: 22s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 11:24:58.508367: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 11:25:04.631802: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/10 [==========================>...] - ETA: 11s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 11:25:10.836088: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 11:25:17.060867: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 169s 11s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 11:25:26.332447: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,64,64,4]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_image() with title of /Users/nathan/workspace/neural_art_bots/audio_transcription/output_images/2023_05_13_11_Cubist_painting_with_abstract_styling_an_s1290_0.png and image shape of (1, 512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading image at path: /Users/nathan/workspace/neural_art_bots/audio_transcription/output_images/2023_05_13_11_Cubist_painting_with_abstract_styling_an_s1290_0.png\n",
      "img: <PIL.PngImagePlugin.PngImageFile image mode=RGB size=512x512 at 0x1463AE110>\n",
      "img type: <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "generating upscale model with input shape of (512, 512) and output shape of (1024, 1024)\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Image saved to: /Users/nathan/workspace/neural_art_bots/audio_transcription/output_images/2023_05_13_11_Cubist_painting_with_abstract_styling_an_s1290_0_upscaled.png\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "plot_images() missing 1 required positional argument: 'titles'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img_generator\u001b[39m.\u001b[39;49mmain(arg_dict)\n",
      "File \u001b[0;32m~/workspace/neural_art_bots/audio_transcription/../stable_diffusion/image_generator_from_text.py:178\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(arg_dict)\u001b[0m\n\u001b[1;32m    175\u001b[0m             upscale_image(output_names[idx], upscale_factor)\n\u001b[1;32m    176\u001b[0m         idx \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 178\u001b[0m     keras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mclear_session()  \u001b[39m# Clear session to preserve memory\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[39mif\u001b[39;00m (plot_output):\n\u001b[1;32m    181\u001b[0m     plot_images(image)\n",
      "\u001b[0;31mTypeError\u001b[0m: plot_images() missing 1 required positional argument: 'titles'"
     ]
    }
   ],
   "source": [
    "img_generator.main(arg_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great, that works, but lets try to use a different method to generate image prompts that are a bit less random... \n",
    "Time to call on our old friend GPT =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The show was costing and production was wasting many working hours thinking they were completely unnecessary.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "import requests\n",
    "\n",
    "assert os.environ.get('OPENAI_API_KEY') is not None, 'ERROR, your environment variable OPENAI_API_KEY is not set properly'\n",
    "\n",
    "def generatePromptWithGPT(word_memory):\n",
    "    max_tokens = 200\n",
    "    # Create a dictionary to store our headers\n",
    "    prompt = \"Can you please use the following words to create an interesting prompt for stable diffusion image generation? {}\".format(word_memory)\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': 'Bearer ' + os.environ.get('OPENAI_API_KEY')\n",
    "    }\n",
    "    # create the data dictionary for our API call\n",
    "    data = {\n",
    "        'model': 'text-babbage-001',\n",
    "        'temperature': 1.2,\n",
    "        'n': 1,\n",
    "        'max_tokens': max_tokens,\n",
    "        'prompt':  prompt  # TODO, what does the 'role' potion of this dict do?\n",
    "        # 'stop' : ';'\n",
    "    }\n",
    "    # print(\"Our data dict is as follows: \", data)\n",
    "    # print(\"Our header dict is as follows: {}\".format(headers))\n",
    "    # Pose the debate topic question to our first debater\n",
    "    # print(\"{} is generating a response to the prompt of: {}\".format(\n",
    "    #    debater_params['name'], topic))\n",
    "    response = requests.post(\n",
    "        'https://api.openai.com/v1/completions', headers=headers, json=data).json()\n",
    "    return response['choices'][0]['text'].replace(\"/n\", \"\")\n",
    "\n",
    "gpt_prompt = generatePromptWithGPT(words)\n",
    "print(gpt_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By using this model checkpoint, you acknowledge that its usage is subject to the terms of the CreativeML Open RAIL-M license at https://raw.githubusercontent.com/CompVis/stable-diffusion/main/LICENSE\n",
      "prompts are: ['\\n\\nThe show was costing and production was wasting many working hours thinking they were completely unnecessary.']\n",
      "prompts are ['\\n\\nThe show was costing and production was wasting many working hours thinking they were completely unnecessary.']\n",
      "image name generated: /Users/nathan/workspace/neural_art_bots/audio_transcription/output_images/2023_05_13_12_\n",
      "\n",
      "The_show_was_costing_and_production_wa_s1290_0.png\n",
      "output names: ['/Users/nathan/workspace/neural_art_bots/audio_transcription/output_images/2023_05_13_12_\\n\\nThe_show_was_costing_and_production_wa_s1290_0.png']\n",
      "creating batch # 0 for prompt \n",
      "\n",
      "The show was costing and production was wasting many working hours thinking they were completely unnecessary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 12:23:32.957600: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [1,77]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-13 12:23:39.370329: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [1,77]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-13 12:24:03.923567: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 12:24:56.788329: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/10 [==>...........................] - ETA: 12:21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 12:25:01.840743: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 12:25:06.904259: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/10 [=====>........................] - ETA: 1:22 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 12:25:12.199290: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 12:25:18.100288: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/10 [========>.....................] - ETA: 1:35"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 12:25:29.073458: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 12:25:42.660113: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/10 [===========>..................] - ETA: 1:34"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 12:25:49.321457: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 12:25:55.237765: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/10 [==============>...............] - ETA: 1:15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 12:26:02.029768: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 12:26:14.576339: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/10 [=================>............] - ETA: 1:16"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 12:26:37.790093: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 12:26:59.652590: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/10 [====================>.........] - ETA: 1:07"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 12:27:17.544410: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 12:27:26.784996: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8/10 [=======================>......] - ETA: 43s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 12:27:35.101590: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 12:27:50.063193: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/10 [==========================>...] - ETA: 22s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 12:28:01.699839: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-05-13 12:28:09.770420: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [1,77,768]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 277s 22s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 12:28:20.673954: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1,64,64,4]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_image() with title of /Users/nathan/workspace/neural_art_bots/audio_transcription/output_images/2023_05_13_12_\n",
      "\n",
      "The_show_was_costing_and_production_wa_s1290_0.png and image shape of (1, 512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading image at path: /Users/nathan/workspace/neural_art_bots/audio_transcription/output_images/2023_05_13_12_\n",
      "\n",
      "The_show_was_costing_and_production_wa_s1290_0.png\n",
      "img: <PIL.PngImagePlugin.PngImageFile image mode=RGB size=512x512 at 0x147B97880>\n",
      "img type: <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "generating upscale model with input shape of (512, 512) and output shape of (1024, 1024)\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "Image saved to: /Users/nathan/workspace/neural_art_bots/audio_transcription/output_images/2023_05_13_12_\n",
      "\n",
      "The_show_was_costing_and_production_wa_s1290_0_upscaled.png\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "plot_images() missing 1 required positional argument: 'titles'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m arg_dict[\u001b[39m'\u001b[39m\u001b[39mprompts\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [gpt_prompt]\n\u001b[0;32m----> 2\u001b[0m img_generator\u001b[39m.\u001b[39;49mmain(arg_dict)\n",
      "File \u001b[0;32m~/workspace/neural_art_bots/audio_transcription/../stable_diffusion/image_generator_from_text.py:178\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(arg_dict)\u001b[0m\n\u001b[1;32m    175\u001b[0m             upscale_image(output_names[idx], upscale_factor)\n\u001b[1;32m    176\u001b[0m         idx \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 178\u001b[0m     keras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mclear_session()  \u001b[39m# Clear session to preserve memory\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[39mif\u001b[39;00m (plot_output):\n\u001b[1;32m    181\u001b[0m     plot_images(image)\n",
      "\u001b[0;31mTypeError\u001b[0m: plot_images() missing 1 required positional argument: 'titles'"
     ]
    }
   ],
   "source": [
    "arg_dict['prompts'] = [gpt_prompt]\n",
    "img_generator.main(arg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84f100e172d30523e09c9ea3b146d7b4e44e98c1b89071d9f6625876d1cbe325"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
